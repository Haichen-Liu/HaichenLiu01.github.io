---
permalink: /
title: "About me"
layout: single        # âœ… ä½¿ç”¨æ ‡å‡†å•é¡µå¸ƒå±€
author_profile: true  # âœ… ä¿ç•™å·¦ä¾§ä½œè€…æ 
classes: wide         # âœ… æ‰©å±•å³ä¾§æ­£æ–‡åŒºåŸŸ
redirect_from:
  - /about/
  - /about.html
---

Hello! I am currently pursuing my masterâ€™s degree at the [School of Engineering](https://eng.ed.ac.uk/), [University of Edinburgh](https://www.ed.ac.uk/), where Iâ€™m fortunate to be supervised by Prof. [Sotirios Tsaftaris](https://eng.ed.ac.uk/about/people/professor-sotirios-tsaftaris), with co-supervision from Dr. [Panos Dimitrakopoulos](https://streetakos.github.io/webpage/) and Mr. [Konstantinos Vilouras](https://vios.science/team/kostas).

My primary research interests lie in machine learning, image processing, computer vision, and digital signal processing. I am particularly interested in enhancing the efficiency and accuracy of AI algorithms, with applications spanning object detection and human pose estimation. Throughout my academic journey, I have sought to bridge theoretical knowledge and practical applications. My work has included object detection models such as  [YOLO](https://github.com/ultralytics/ultralytics), [DETR](https://github.com/facebookresearch/detr), [SSD](https://github.com/amdegroot/ssd.pytorch), and [Faster R-CNN](https://github.com/jwyang/faster-rcnn.pytorch), as well as human pose estimation methods like [YOLOPose](https://arxiv.org/abs/2204.06806), [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose), and [VideoPose3D](https://github.com/facebookresearch/VideoPose3D).  

---

Before pursuing my masterâ€™s studies, I had the privilege of working with Prof. [Chengguang Sun](https://dianzi.tute.edu.cn/info/1291/25242.htm), Prof. [Jianqiang Mei](https://dianzi.tute.edu.cn/info/1291/25232.htm), Prof. [Dan Cheng](https://dianzi.tute.edu.cn/info/1291/25162.htm), and Prof. [Xuewen Ding](https://dianzi.tute.edu.cn/info/1291/25172.htm)  on topics related to the internet of things, embedded systems, image processing, and machine learning. From 2019 to 2023, under the supervision of Prof. Chengguang Sun, I completed my undergraduate studies in Electronic Information Engineering, during which I participated in several electronic and computer science competitions. Prof. Sun also supervised my Bachelorâ€™s thesis, â€œDesign of Intelligent Greenhouse Garden Based on AIoT Technology,â€ which was awarded The Excellent Graduation Project (Thesis) in 2023 (Grade: 94 points, Ranked First in the School of Electronic Engineering). Through this experience, I developed a strong foundation in project design, system implementation, and technical writing. From 2023 to 2025, under the guidance of Prof. Jianqiang Mei, I further strengthened my skills in academic research and English scientific writing. He taught me how to read and analyze English literature effectively, organize research content, and write academic papers in English. Under his supervision, I also broadened my expertise in deep learning and computer vision techniques, which laid a strong foundation for my later research.  

---

### ğŸ” Current Research

I am currently conducting research on Visual Anagrams and Optical Illusions, exploring how **generative diffusion models** and **Generative Adversarial Networks** can be used to create multi-view optical illusions and uncover new insights into perceptual ambiguity. This research focuses on potential applications in medical image analysis, human visual perception modeling, and AI-based diagnostic image synthesis. The goal is to understand how **generative AI** models can represent and reproduce ambiguous visual patterns, offering perspectives on both human cognition and artificial perception systems.

### ğŸ”— Related Projects
- [**Visual Anagrams**](https://github.com/dangeng/visual_anagrams) â€” studying multi-view optical illusions generated by diffusion models  
- [**GAN**](https://github.com/eriklindernoren/PyTorch-GAN) â€” exploring generative enhancement for diagnostic and low-light imaging  
- [**Hugging Face Diffusers**](https://github.com/huggingface/diffusers) â€” implementing diffusion-based synthesis for perceptually consistent visual outputs  

---

### ğŸ¨ Personal Interests

I also enjoy **anime**, which inspires my interest in artistic image generation and creative AI.  

- Exploring artistic style generation with [AniGAN](https://github.com/bing-li-ai/AniGAN), [AnimeGAN](https://github.com/TachibanaYoshino/AnimeGAN), and [MangaGAN](https://github.com/nikitaa30/Manga-GAN). 

---

### ğŸš€ Looking Ahead

I am excited to continue exploring the intersections of **machine learning, image processing, computer vision, and digital signal processing**, and to contribute to research that is both scientifically impactful and practically meaningful.

If you would like to connect or discuss potential collaborations, please feel free to reach me at:  
ğŸ“§ 18805644868@139.com | ğŸ“§ s2604458@ed.ac.uk  

---

### ğŸ“š For More Information
For an up-to-date list of my scholarly works, including publications and citations, please visit my  
[**Google Scholar**](https://scholar.google.com/citations?hl=en&user=wv4jqDEAAAAJ) profile.  

Welcome to explore and connect! ğŸŒŸ





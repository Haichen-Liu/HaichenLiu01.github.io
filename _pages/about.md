---
permalink: /
title: "About me"
layout: single        # âœ… ä½¿ç”¨æ ‡å‡†å•é¡µå¸ƒå±€
author_profile: true  # âœ… ä¿ç•™å·¦ä¾§ä½œè€…æ 
classes: wide         # âœ… æ‰©å±•å³ä¾§æ­£æ–‡åŒºåŸŸ
redirect_from:
  - /about/
  - /about.html
---

Hello! I am currently pursuing my masterâ€™s degree at the [School of Engineering](https://eng.ed.ac.uk/), [University of Edinburgh](https://www.ed.ac.uk/), where Iâ€™m fortunate to be supervised by Prof. [Sotirios A. Tsaftaris](https://eng.ed.ac.uk/about/people/professor-sotirios-tsaftaris), with co-supervision from Dr. [Panos Dimitrakopoulos](https://vios.science/team/panos) and Mr. [Konstantinos Vilouras](https://vios.science/team/kostas).

My primary research interests lie in machine learning, image processing, computer vision, and digital signal processing. I am particularly interested in enhancing the efficiency and accuracy of AI algorithms, with applications spanning object detection and human pose estimation. Throughout my academic journey, I have sought to bridge theoretical knowledge and practical applications. My work has included object detection models such as  [YOLO](https://github.com/ultralytics/ultralytics), [DETR](https://github.com/facebookresearch/detr), [SSD](https://github.com/amdegroot/ssd.pytorch), and [Faster R-CNN](https://github.com/jwyang/faster-rcnn.pytorch), as well as human pose estimation methods like [YOLOPose](https://arxiv.org/abs/2204.06806), [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose), and [VideoPose3D](https://github.com/facebookresearch/VideoPose3D).  

---

Before pursuing my masterâ€™s studies, I had the privilege of working with Prof. [Chengguang Sun](https://dianzi.tute.edu.cn/info/1291/25242.htm), Prof. [Jianqiang Mei](https://dianzi.tute.edu.cn/info/1291/25232.htm), Prof. [Dan Cheng](https://dianzi.tute.edu.cn/info/1291/25162.htm), and Prof. [Xuewen Ding](https://dianzi.tute.edu.cn/info/1291/25172.htm)  on topics related to the Internet of Things, Embedded Systems, Image Processing, and Machine Learning. Under the supervision of Prof. Sun, I completed my undergraduate thesis â€œDesign of Intelligent Greenhouse Garden Based on AIoT Technologyâ€, which was awarded The Excellent Graduation Project (Thesis) in 2023. Later, under Prof. Meiâ€™s supervision, I further strengthened my research and academic writing skills in deep learning and computer vision. 

---

### ğŸ” Current Research

I am currently conducting research on **Visual Anagrams and Optical Illusions** at the University of Edinburgh, under the supervision of Prof. Tsaftaris, Dr. Dimitrakopoulos, and Mr. Vilouras. My work investigates how **generative diffusion models** and **Generative Adversarial Networks (GANs)** can be used to create **multi-view optical illusions** that explore the boundaries between **visual perception** and **machine generation**. This research focuses on understanding how generative models represent **ambiguous visual information**, and how contentâ€“style and contentâ€“content interactions influence the creation of perceptually coherent yet semantically distinct images. The ultimate goal is to provide insights into **human perception** and **AI interpretability** through the lens of generative modeling.

#### ğŸ–¼ï¸ Visual Anagram Examples

| **Experiment 1** | **Experiment 2** | **Experiment 3** |
| :---: | :---: | :---: |
| <img src="{{ '/images/3.png'  | relative_url }}" width="100%"> | <img src="{{ '/images/6.png'  | relative_url }}" width="100%"> | <img src="{{ '/images/7.png'  | relative_url }}" width="100%"> |
| *Identity View (Original)* | *Identity View (Original)* | *Identity View (Original)* |
| <img src="{{ '/images/3I.png' | relative_url }}" width="100%"> | <img src="{{ '/images/6I.png' | relative_url }}" width="100%"> | <img src="{{ '/images/7I.png' | relative_url }}" width="100%"> |
| *Transformed View (Illusion)* | *Transformed View (Illusion)* | *Transformed View (Illusion)* |

#### ğŸ¥ Animation (Transformation Process)

| **Experiment 1** | **Experiment 2** | **Experiment 3** |
| :---: | :---: | :---: |
| <video width="100%" autoplay loop muted playsinline controls><source src="{{ '/images/3.mp4' | relative_url }}" type="video/mp4"></video> | <video width="100%" autoplay loop muted playsinline controls><source src="{{ '/images/6.mp4' | relative_url }}" type="video/mp4"></video> | <video width="100%" autoplay loop muted playsinline controls><source src="{{ '/images/7.mp4' | relative_url }}" type="video/mp4"></video> |
| *Transformation Video* | *Transformation Video* | *Transformation Video* |




### ğŸ”— Related Projects
- [**Visual Anagrams**](https://github.com/dangeng/visual_anagrams) â€” exploring multi-view optical illusion generation with diffusion models  
- [**GAN**](https://github.com/eriklindernoren/PyTorch-GAN) â€” experimenting with adversarial frameworks for visual realism and feature disentanglement  
- [**Hugging Face Diffusers**](https://github.com/huggingface/diffusers) â€” implementing and customizing diffusion-based generation for perceptual alignment studies  


---

### ğŸ¨ Personal Interests

I also enjoy **anime**, which inspires my interest in artistic image generation and creative AI.  

- Exploring artistic style generation with [AniGAN](https://github.com/bing-li-ai/AniGAN), [AnimeGAN](https://github.com/TachibanaYoshino/AnimeGAN), and [MangaGAN](https://github.com/nikitaa30/Manga-GAN). 

---

### ğŸš€ Looking Ahead

I am excited to continue exploring the intersections of **machine learning, image processing, computer vision, and digital signal processing**, and to contribute to research that is both scientifically impactful and practically meaningful.

If you would like to connect or discuss potential collaborations, please feel free to reach me at:  
ğŸ“§ 18805644868@139.com | ğŸ“§ s2604458@ed.ac.uk  

---

### ğŸ“š For More Information
For an up-to-date list of my scholarly works, including publications and citations, please visit my  
[**Google Scholar**](https://scholar.google.com/citations?hl=en&user=wv4jqDEAAAAJ) profile.  

Welcome to explore and connect! ğŸŒŸ




